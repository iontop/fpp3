---
title: "Chap5_8"
author: "J.H AHN"
date: '2021 12 8 '
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(fpp3)

knitr::opts_chunk$set(echo = TRUE)
```

## 5.8 Evaluating point forecast accuracy


### Training and test sets

잔차의 크기가 중요한 것이 아니라 예측이 얼마나 정확하게 되느냐가 중요한 평가기준이다.  
예측 정확도는 예측 모델을 이용해 새로운 데이터로 예측할 때 얼마나 잘 예측하는지로써 평가된다. 


![](https://otexts.com/fpp3/fpp_files/figure-html/traintest-1.png)



모델을 선택할 때 사용 가능한 데이터를 **Training set**과 **Test set**으로 나눠서 사용하는 것이 일반적이다.  
Training set은 예측 모델의 매개변수들을 추정하는데 사용하고 Test set은 Training set을 이용하여 만든 모델을 평가하는데 사용된다.  
Test set은 예측 모델을 만드는데는 사용되지 않기 때문에 새로운 데이터를 예측할 때 얼마나 잘 예측할 수 있는지에 대한 지표를 보여줄 수 있어야 한다.  




Test set은 일반적으로 전체 데이터의 20%정도를 사용하지만 상황에 따라 다르게 배분할 수 있다.  
Training set과 Test set으로 나눠서 예측 모델을 만들 때는 아래 사항을 유의해야 한다.  


* Training set에 잘 맞는(fit) 모델이 반드시 새로운 데이터에 대한 예측을 잘 하는 것은 아니다. (overfitting)  
* 충분한 매개변수가 있는 모델을 사용하면 항상 완벽하게 적합(fit)시킬 수 있다.  
* 모델이 데이터에 과도하게 fit되는 것은 데이터에서 Systematic pattern을 인식하지 못하는 것만큼 나쁜 것이다.  


### Functions to subset a time series

시계열 데이터에서 특정시간대를 추출하고 싶을 때 `function()`함수를 사용하면 된다.  
Evaluation을 위해 data를 나눌 때, `filter()`함수를 사용하면 된다.  
나누는 방법이 여러가지가 있겠지만 개인적으로는 `initial_time_split()`함수를 사용하는 방법을 선호한다.


예를 들어
```{r}
aus_production %>% 
    filter(year(Quarter) >= 1995)

```

1995년 이후의 데이터를 추출한다.  
혹은 `tsibble::filter_index()` 함수를 사용해도 동일한 결과를 얻을 수 있다.  

```{r}
aus_production %>% 
    filter_index("1995 Q1" ~ .)

```


또 다른 유용한 함수로 `slice()`가 있는데 이것은 필요한 범위만큼 잘라내어 가져오게 해 준다.  
예를 들어 20개전 관측치 (1년 = 4분기이므로 현재부터 이전 5년치)를 추출하고 싶다면 아래와 같이 쓸 수 있다.  

```{r}
aus_production %>% 
    slice(n()-19:0)

```

`slice()`함수는 그룹별로도 사용할 수 있는데 그룹으로 묶은 다음 필요한 그룹의 부분만 추출할 수도 있음.
아래 예는 State, Industry 그룹별로 12개씩 데이터를 추출한 예임.  


```{r}
aus_retail %>% 
    group_by(State, Industry) %>% 
    slice(1:12)

```



### Forecast errors

예측 **오차(error)**는 관측값과 예측값 간의 차이이다.  
여기서 오차는 실수를 의미하는 것이 아닌 관찰에서 예측할 수 없는 것을 의미한다.  

$$e_{T+h} = y_{T+h} - \hat{y}_{T+h|T}$$

$\{y_1,\dots,y_T\}$는 Training set에서 주어지는 것이고, $\{y_{T+1},y_{T+2},\dots\}$는 Test set에서 주어지는 값이다.  


예측 오차는 두 가지 면에서 잔차(residuals)와 다르다.  


1. residulas은 training set에서 계산되고, errors는 test set에서 계산된다.  
2. residulas은 one-step forecast를 기반으로 하는 반면, errors는 multi-step forecast에 포함된다.  

예측 오차는 다양한 방식으로 표시하여 예측 정확도를 측정할 수 있다.  



### Scale-dependent errors

예측 오차는 데이터와 동일한 스케일을 가진다.  
따라서 $e_t$로만 측정된 Accuracy는 스케일에 따라 달라지며 다른 단위계를 포함하는 데이터를 비교하는데는 사용할 수 없다.  

오차의 절대값 혹은 제곱값으로 나타내는 scale-dependent한 가장 일반적으로 사용되는 측정치는 아래와 같다.  

$$\begin{align*}
  \text{Mean absolute error: MAE} & = \text{mean}(|e_{t}|),\\
  \text{Root mean squared error: RMSE} & = \sqrt{\text{mean}(e_{t}^2)}.
\end{align*}$$


단일 시계열 또는 동일한 단위계가 사용된 여러 시계열의 예측값을 비교할 때 MAE는 이해하기 쉽고, 계산이 용이하여 널리 사용된다.  
MAE를 최소화하는 예측방법은 중간값(median)예측으로 이어지는 반면 RMSE를 최소화하면 평균(mean)예측이 된다.  
RMSE가 해석하기는 어렵지만 더 널리 사용된다.  



### Percentage errors

백분율 오차는 $p_{t} = 100 e_{t}/y_{t}$로 나타낼 수 있다.  
백분율 오차는 단위가 없는 이점이 있어 테이터 간 예측 성능을 비교하는데 자주 사용된다.  
가장 일반적으로 사용되는 MAPE는 아래와 같이 구할 수 있다.  

$$\text{Mean absolute percentage error: MAPE} = \text{mean}(|p_{t}|)$$

MAPE는 $y_{t}=0$이 되거나 $y_t$가 0에 가까워지면 무한대에 가까운 값을 보여주는 단점이 있다.  
또 다른 문제로 측정단위에 의미있는 0이 있다고 가정하는 것이다.  
예를 들어 화씨나 섭씨 온도 예측의 정확도를 측정할 때 백분율 오차는 아무런 의미가 없다.  
온도에는 임의의 영점이 존재하는 것이 아니기 때문이다.  


또한 MAPE는 positive errors 보다 negative errors에 더 큰 페널티를 부과한다는 단점이 있다. 
이런 현상은 M3 forecasting competition에서 사용했던 Armstrong (1978, p. 348)이 제안한 소위 "대칭(symmetric)"MAPE(=sMAPE)라는 개념을 만들어냈다.  

$$\text{sMAPE} = \text{mean}\left(200|y_{t} - \hat{y}_{t}|/(y_{t}+\hat{y}_{t})\right)$$


그러나 만약 $y_t$가 0에 가까워지면 $\hat y_t$도 0에 가까워지게 되므로 여전히 0에 가까운 숫자로 나눠야 하는 계산의 불안정이 생길 수 있다.  또한 sMAPE값이 음수가 나올 수도 있기 때문에 실제로는 "백분율 오차의 절대값"이 아니다.  
이 때문에 Hyndman & Koehler(2006)는 sMAPE를 사용하지 말 것을 권장하고 있다.  




### Scaled errors

Hyndman & Koehler(2006)는 다른 단위를 사용하여 계열에 대한 예측 정확도를 비교할 때 백분율 오차를 사용하는 대안으로 척도 오차(scaled errors)를 제안했다.  
간단한 예측 방법에서 *training* MAE를 기반으로 하는 오차를 계산하는 방법이다.  


비계절성 시계열의 경우 척도 오차를 정의하는 유용한 방법으로 naive forecast를 사용한다.  

$$q_{j} = \frac{\displaystyle e_{j}}
    {\displaystyle\frac{1}{T-1}\sum_{t=2}^T |y_{t}-y_{t-1}|}$$
    

분자와 분모는 모두 원래 데이터의 scale을 사용하기 때문에 $q_{j}$는 scale과 무관한다.  
만약 training set에서 계산된 average one-step naive forecast보다 예측이 더 좋으면 1보다 작은 값이 나타내고, 반대로 training set에서 계산된 average one-step naive forecast보다 예측이 더 나쁘면 1보다 더 큰 수를 나타낸다.  


계절성이 있는 시계열에서, 척도 오차는 seasonal naive forecasts를 이용하여 아래와 같이 정의할 수 있다.  

$$q_{j} = \frac{\displaystyle e_{j}}
    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|}$$


*mean absolute scaled error*는 간단하게 아래와 같이 나타낼 수 있다.

$$\text{MASE} = \text{mean}(|q_{j}|)$$

비슷하게 *root mean squared scaled error*도 아래와 같이 나타낼 수 있다.  

$$\text{RMSSE} = \sqrt{\text{mean}(q_{j}^2)}$$

$$q^2_{j} = \frac{\displaystyle e^2_{j}}
    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T (y_{t}-y_{t-m})^2}$$


여기서 $m=1$로 두면 계절성 없는 데이터(non-seasonal data)가 된다.  



### Examples

```{r}
recent_production <- aus_production %>%
    filter(year(Quarter) >= 1992)

recent_production

```


```{r}
beer_train <- recent_production %>%
    filter(year(Quarter) <= 2007)

beer_train

```


```{r}
beer_fit <- beer_train %>%
    model(
        Mean = MEAN(Beer),
        `Naïve` = NAIVE(Beer),
        `Seasonal naïve` = SNAIVE(Beer),
        Drift = RW(Beer ~ drift())
    )

beer_fit

```


```{r}
beer_fc <- beer_fit %>%
    forecast(h = 10)

beer_fc

```



```{r}
beer_fc %>%
    autoplot(
        aus_production %>% filter(year(Quarter) >= 1992),
        level = NULL
    ) +
    labs(
        y = "Megalitres",
        title = "Forecasts for quarterly beer production"
    ) +
    guides(colour = guide_legend(title = "Forecast"))

```


위 plot은 2007년 말까지 데이터를 추출하여 분기별 호주 맥주 생산량을 네가지 예측 방법을 사용하여 예측한 결과를 보여준다.  
아래는 이 기간에 대한 예측 정확도를 계산한 결과이다.  


```{r}
accuracy(beer_fc, recent_production)


```


`accuracy()` 함수는 다양한 정확도 측정값을 계산할 때 사용한다.  
위 예시에서 beer_fc는 예측모델, recent_production은 예측 기간이 포함된 데이터를 의미한다.  

plot을 보면 seasonal naive method가 가장 적합해 보이지만 여전히 더 개선할 수 있는 방법이 있다.  
때로는 어떤 정확도 측정값으로 평가하느냐에 따라 다른 결론에 이를 수 있다.  
그러나 이 경우에는 모든 측정값이 Seasonal naive method가 가장 좋은 것으로 평가하고 있다.  



계절성이 없는 구글의 주가를 예측한 예시를 보자.  
아래 예시는 2015년 종가와 세가지 기법으로 예측한 2016년 1월 주가를 보여준다.  

```{r}
# Re-index based on trading days
google_stock <- 
    gafa_stock %>%
    filter(Symbol == "GOOG", year(Date) >= 2015) %>%
    mutate(day = row_number()) %>%
    update_tsibble(index = day, regular = TRUE)

# Filter the year of interest
google_2015 <- 
    google_stock %>% 
    filter(year(Date) == 2015)

google_2015

```


```{r}
google_jan_2016 <- 
    google_stock %>% 
    filter(yearmonth(Date) == yearmonth("2016 Jan"))

google_jan_2016

```



```{r}
google_fit <- google_2015 %>%
    model(
        Mean = MEAN(Close),
        `Naïve` = NAIVE(Close),
        Drift = RW(Close ~ drift())
    )

google_fit

```


```{r}
google_fc <- google_fit %>%
    forecast(google_jan_2016)

google_fc

```


```{r}
google_fc %>%
    autoplot(bind_rows(google_2015, google_jan_2016),
             level = NULL) +
    labs(y = "$US",
         title = "Google closing stock prices from Jan 2015") +
    guides(colour = guide_legend(title = "Forecast"))

```


```{r}
accuracy(google_fc, google_stock)

```

naive method가 가장 좋은 결과를 보여준다는 것을 확인할 수 있다.  





*

































