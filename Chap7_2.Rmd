---
title: "Chap7_2"
author: "J.H AHN"
date: '2021 12 16 '
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
library(fpp3)

knitr::opts_chunk$set(echo = TRUE)
```

## 7.2 Least squares estimation


실제로 데이터를 보더라도 우리는 계수 $\beta_0,\beta_1, \dots, \beta_k$는 알 수 없고 데이터로 부터 추정을 해야 한다.  


최소 제공 원리는 오차의 제곱합(sum of the squared errors)을 최소화시켜 효과적으로 계수를 구할 수 있게 해주는 방법이다.

$$\sum_{t=1}^T \varepsilon_t^2 = \sum_{t=1}^T (y_t -
  \beta_{0} - \beta_{1} x_{1,t} - \beta_{2} x_{2,t} - \cdots - \beta_{k} x_{k,t})^2$$
  
 
이런 방법을 **최소자승법(least squares)**이라 한다. 가장 좋은 계수를 찾는 것을 데이터에 모델을 적합(fitting)한다고 하거나, 모델을 학습(learning) 혹은 훈련(training)한다고 표현한다.  
이런 방식으로 Fig 7.3에서 선을 얻을 수 있었다.  

우리가 추정하는 계수(estimated coefficients)를 참조할 때, 보통 $\hat\beta_0, \dots, \hat\beta_k$과 같이 표기한다. 이에 대한 방정식은 Chap7_9를 참조하기 바란다.


`TSLM()`함수는 시계열 데이터를 선형 회귀 모델로 적합하는데 사용한다.  
선형 모델에 더 광범위하게 사용되는 비스한 역할을 하는 `lm()`함수도 있으나 `TsLM()`함수는 시계열을 다루기 위한 추가적인 기능을 가지고 있다.  


### Example: US consumption expenditure

US consumption 데이터의 다중 선형 회귀 모델은 아래와 같다.  


$$y_t=\beta_0 + \beta_1 x_{1,t}+ \beta_2 x_{2,t}+ \beta_3 x_{3,t}+ \beta_4 x_{4,t}+\varepsilon_t,$$

$y$는 개인의 소비지출 %변화 이며, $x_1$은 개인 가처분 소득 %변화, $x_2$는 산업생산의 %변화, $x_3$는 개인 저축의 %변화, $x_4$는 실업율 변화를 나타낸다.


아래 결과는 fitted model에 대한 정보를 제공한다.  
coefficient의 첫번째 열은 각 $\beta$ coefficient의 추정치고, 두번째 열은 표준오차(standard error, 즉 유사한 데이터 셋에서 $\beta$를 반복적으로 추정할 때 얻을 수 있는 표준편차)이다.  표준오차는 추정된 $\beta$의 불확실성을 나타낸다.  


```{r}
fit_consMR <- 
    us_change %>% 
    model(tslm = TSLM(Consumption ~ Income + Production +
                          Unemployment + Savings))

report(fit_consMR)

```


예측을 목적으로 할 때 마지막 두 열(t-value, Pr(>|t|))은 크게 신경쓰지 않아도 된다.  
"t value"는 추정된 $\beta$와 std. Error와의 비율을 나타내며, 마지막 열은 p-value (추정된 $\beta$가 Consumption과 다른 predictor들간에 실제 관계가 없는 경우를 나타내는 확률)이다.  


이는 각 predictor의 효과에 대해서 연구할 때는 유용하지만 예측에서는 크게 중요하지 않다.  



### Fitted values


회귀 방정식에서 추정된 계수를 사용하고 오차항을 0으로 만들어 $y$ 값을 얻을 수 있다.  

$$\begin{equation}
  \hat{y}_t = \hat\beta_{0} + \hat\beta_{1} x_{1,t} + \hat\beta_{2} x_{2,t} + \cdots + \hat\beta_{k} x_{k,t}.
  \tag{7.2}
\end{equation}$$

$t=1,\dots,T$에 따른 $x_{1,t},\dots,x_{k,t}$를 넣으면 *fitted values*로 training set 내에서의 $y_t$를 얻을 수 있다. 중요한 것은 이 $y_t$는 모델을 추정하기 위해 사용하는 데이터 셋의 예측값이지 우리가 찾아야 하는 실제 예측값 $y$가 아니다.  


다음 그림은 US consumption에 대한 fitted value와 실제 값을 보여준다.  
Fig 7.6에서는 fitted value가 실제와 상당히 가깝다는 것을 보여주고, 이는 Fig 7.7의 Scatterplot에 의해 강한 양의 관계가 있다는 것을 확인할 수 있다.  


'fabletools::augment()`는 fitted model로 fitted value, residuals와 같은 response variable을 data.frame(tsibble) 형태로 출력해준다. residuals은 response residuals(bak-transformed)와 innovation residuals(transformed)로 구분하여 출력  



```{r}
augment(fit_consMR) %>% 
    ggplot(aes(x = Quarter)) +
    geom_line(aes(y = Consumption, color = "Data")) +
    geom_line(aes(y = .fitted, color = "Fitted")) +
    labs(title = "Fig 7.6-Percent change in US consumption expenditure",
         y = NULL)

```



```{r}
augment(fit_consMR) %>% 
    ggplot(aes(x = Consumption, y = .fitted)) +
    geom_point() +
    geom_abline(lty = 2, color = "#006400") +
    labs(title = "Fig 7.7-Percent change in US consumption expenditure",
         x = "Data (actual values)",
         y = "Fitted (predicted values)")



```




### Goodness-of-fit

선형회귀모델이 데이터에 얼마나 잘 맞는지 확인할 수 있는 가장 일반적인 방법은 결정계수($R^2$)를 사용하는 것이다.  

이것은 관찰된 $y$값과 예측된 $\hat{y}$ 사이의 상관관계의 제곱을 나타낸 것으로 아래와 같이 계산할 수 있다.  

$$R^2 = 1 - \frac{SSR}{SST} = \frac{\sum(\hat{y}_{t} - \bar{y})^2}{\sum(y_{t}-\bar{y})^2}$$


여기서 합계는 모든 관측치에 대한 것으로 회귀 모델에 의해 설명되는 예측변수의 변동 비율을 나타낸다.  (Sum of Squared Total = SST, Sum of Squared Residual = SSR)


단순회귀모델에서 $R^2$값은 $y$와 (절편이 포함된)$x$사이의 상관관계의 제곱값과 같다.  

$R^2$가 크면 좋기는 하다. 커서 나쁠 건 없다. 하지만 크다고 무조건 좋은 것도 아니고 작다고 나쁜 것도 아니다. $R^2$가 아무리 높아도 시계열모형에서의 허구적 회귀와 같은 경우라면 아무 의미가 없다.  


선형모형의 목적이 종속변수의 예측에 있는 것이라면 높은 것이 좋다. $R^2$자체가 선형모형에서 종속변수의 움직임을 얼마나 잘 나타내는지를 보여주는 지표이기 때문이다. 이 때에는 $R^2$와 예측 $R^2$(predicted $R^2$)를 함께 쓰는 경우가 많다. 예를 들어 선형모형으로 주가예측을 한다거나, 제품을 생산할 때에는 $R^2$가 커야한다.  


반면 목적이 변수간 관계 추정에 있다면 $R^2$가 낮아도 큰 상관은 없다. 선형모형에서 고전적 가정들(등분산, 자기상관성 없음, 내생성 없음 등)이 성립하면 변수간 관계를 추정하는데에는 전혀 문제가 없기 때문이다. 사회과학 모형은 시계열, 패널 데이터가 아닌 이상 결정계수가 낮을 가능성이 큰데, 모형을 잘 설정하고 적절한 추정방법을 사용했다면 $R^2$가 작더라도 낙담할 필요없다. 



### Example: US consumption expenditure


```{r}
report(fit_consMR)

```


Fig 7.7에서는 실제값과 적합값을 표시했는데 이 두 값의 상관관계는 'Multiple R-squared: 0.7683', 'Adjusted R-squared: 0.7635'으로 계산된다.  
이 경우 모델은 소비 데이터 변동의 76.8%를 설명할 수 있다는 뜻이다.  



### Standard error of the regression

모델이 데이터를 얼마나 잘 fitting시켰는지 알 수 있는 또 다른 측정값으로 Residual standard error(잔차 표준 오차)값이 있다. 예시의 fitted model의 Residual standard error는 0.3102로 나타났다.  


Residual standard error는 아래 식으로 계산된다.


$$\begin{equation}
  \hat{\sigma}_e=\sqrt{\frac{1}{T-k-1}\sum_{t=1}^{T}{e_t^2}},
  \tag{7.3}
\end{equation}$$


여기서 $k$는 모델이 가지고 있는 predictor 갯수이다. $k+1$개의 parameter(intercept도 하나의 predictor로 보기 때문에 빼줘야 한다.)로 예측했기 때문에 $T-k-1$로 나눠야 하는 것에 주의해야 한다.  

표준오차는 모델이 생성하는 평균 오차의 크기와 관련이 있다. 이 오차를 $y$의 표본 평균 또는 $y$의 표준 편차와 비교하여 모델의 정확도를 확인할 수 있다.  

표준오차는 Chap7_6에서 다루게 될 prediction interval을 만들 때 사용된다.



---









