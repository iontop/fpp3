---
title: "Chap5_5"
author: "J.H AHN"
date: '2021 12 7 '
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(fpp3)

knitr::opts_chunk$set(echo = TRUE)
```

## 5.5 Distributional forecasts and prediction intervals

### Forecast distributions

확률분포를 사용하여 예측의 불확실성을 나타내고 피팅된 모델(fitted model)을 사용하여 가능한 미래값을 관찰할 확률(probability)을 설명한다.\
대부분의 시계열 모델은 정규 분포 예측을 생성하는데 이는 가능한 미래값의 분포가 정규 분포를 따른다고 가정하는 것이다.

### Prediction intervals

예측 구간은 $y_t$가 지정된 확률로 있을 것으로 예상되는 구간을 의미한다. 예를 들어 미래 관측치의 분포가 정상(normal)이라고 가정하면 $h$단계 예측에 대한 95% 예측구간(prediction interval)은 아래와 같다.

$$\hat{y}_{T+h|T} \pm 1.96 \hat\sigma_h$$

$\hat\sigma_h$는 $h$단계 예측 분포의 표준편차 예측치이다.\
좀 더 일반적으로 표현하면 예측 구간은 아래와 같이 쓸 수 있다.

$$\hat{y}_{T+h|T} \pm c \hat\sigma_h$$

$c$는 예측 커버리지(coverage probability)에 따라 달라지고, 일반적으로 80% intervals과 95% intervals을 사용한다.\
예측 커버리지에 따른 $c$값은 아래와 같다.  

|Percentage|Multiplier|
|:--------:|:--------:|
|99|2.58|
|98|2.33|
|97|2.17|
|96|2.05|
|95|1.96|
|90|1.64|
|85|1.44|
|80|1.28|

### One-step prediction intervals

한 단계 앞을 예측할 때는 예측 분포의 표준편차를 잔차의 표준편차를 이용하여 아래와 같이 예측할 수 있다.  
$$\begin{equation}
  \hat{\sigma} = \sqrt{\frac{1}{T-K}\sum_{t=1}^T e_t^2}, \tag{5.1}
\end{equation}$$

여기서 $K$는 예측기법의 estimated parameter의 수이다.  

예를 들어 구글 주식 데이터`google_2015`를 naive method로 돌렸을 경우 마지막 관측치가 $758.88이므로 다음값은 $758.88로 예측 할 수 있다.  
naive method로부터 잔차의 표준편차는 식(5.1)을 이용하여 11.19라는 것을 알 수 있다.  
그러므로 구글 주식의 다음 값의 95% prediction interval은 아래와 같이 구할 수 있다.  

$$758.88 \pm 1.96(11.19) = [736.9, 780.8]$$

유사한 방식으로 80% prediction interval을 구하면 아래와 같다.  

$$758.88 \pm 1.28(11.19) = [744.5, 773.2]$$

$c$값은 식(5.1)에서 가져온 것이다.  


### Multi-step prediction intervals


prediction intervals의 일반적인 특징은 예측 기간이 증가함에 따라 넓어진다는 것이다.  
즉 더 멀리 예측할 수록 더 많은 불확실성으로 인해 prediction intervals이 넓어진다. 
$\sigma_h$는 일반적으로 $h$에 비례하여 증가한다. (비선형 예측 기법은 이 속성이 없는 경우가 있음)  

prediction intervals을 만들어 내려면 $\sigma_h$ 추정식이 필요하다.  
앞서 one-step prediction ($h=1$)에서는 식(5.1)을 이용하여 예측 표준편차를 구할 수 있었다.  
Multi-step의 경우 더 복잡한 계산이 필요하고, 계산 시 잔차가 상관관계가 없다고 가정한다.  


### Benchmark methods

4가지 벤치마크 기법의 경우 잔차가 상관관계가 없다는 가정을 바탕으로 예측 표준편차를 수학적으로 도출할 수 있음.  
$\hat\sigma_h$가 $h$-step 예측분포의 표준편차를 나타내고 $\hat\sigma$가 식(5.1)로 구한 잔차의 표준편차를 나타낸다면 표(5.2)를 사용할 수 있다. $h=1$이고 $T$가 충분히 크다면 모두 동일한 근사값 $\hat\sigma$가 나온다.  

|Benchmark method|$h$-step forecast standard deviation|
|:--------------:|:--------------------------------:|
|Mean|$\hat\sigma_h = \hat\sigma\sqrt{1 + 1/T}$|
|Naive|$\hat\sigma_h = \hat\sigma\sqrt{h}$|
|Seasonal naive|$\hat\sigma_h = \hat\sigma\sqrt{k+1}$|
|Drift|$\hat\sigma_h = \hat\sigma\sqrt{h(1 + h/T)}$|

(표 5.2)

prediction intervals은 `fable` package를 이용해서 쉽게 계산할 수 있다.  
예를 들어 구글 주가를 naive method로 만든 예측모델의 prediction intervals은 아래와 같다.  

```{r}
# Re-index based on trading days
google_stock <- 
    gafa_stock %>%
    filter(Symbol == "GOOG", year(Date) >= 2015) %>%
    mutate(day = row_number()) %>%
    update_tsibble(index = day, regular = TRUE)

# Filter the year of interest
google_2015 <- 
    google_stock %>% 
    filter(year(Date) == 2015)

google_2015

```


```{r}
google_2015 %>% 
    model(NAIVE(Close)) %>% 
    forecast(h = 10) %>% 
    hilo()

```


'hilo()'함수는 prediction intervals을 예측 분포로 변환해준다.   
기본값으로 80%와 95% prediction intervals을 알려주고 다른 값이 필요하다면 옵션으로 `level =`으로 설정하면 된다.  


```{r}
google_2015 %>% 
    model(NAIVE(Close)) %>% 
    forecast(h = 10) %>% 
    hilo() %>% 
    unpack_hilo(c(`80%`, `95%`))

```


`hilo()`함수를 사용하여 생성된 열의 값을 보고 싶을 때에는 `unpack_hilo()`함수를 사용하면 볼 수 있다.

```{r}
google_2015 %>% 
    model(NAIVE(Close)) %>% 
    forecast(h = 10) %>% 
    autoplot(google_2015) +
    labs(title = "Google daily closing stock price", y = "$US")

```

plotting을 하면 위 그림처럼 prediction intervals은 shade 되어 표시된다.   


### Prediction intervals from bootstrapped residuals  

잔차가 표준분포를 따른다는 가정이 적절하지 않은 경우에 대안으로 Bootstrapping을 사용하는 방법이 있다.  
Bootstrapping을 적용할 때 단 하나의 가정은 잔차는 Constant variance (a.k.a. homoscedasticity, 등분산성)와 상관성을 가지지 않아야 한다는 것이다.  

one-step forecast error는 $e_t = y_t - \hat{y}_{t|t-1}$로 나타낼 수 있고, 이는 $y_t = \hat{y}_{t|t-1} + e_t$로 쓸 수 있다.  
그러므로 시계열의 다음 관측치는 $y_{T+1} = \hat{y}_{T+1|T} + e_{T+1}$로 나타낼 수 있다.  
여기서 $\hat{y}_{T+1|T}$는 one-step forecast이며, $e_{T+1}$는 unknown future error이다.  
future errors를 과거 error와 유사하다고 가정하면, 과거 잔차의 집합에서 샘플링하여 가져온 $e_{T+1}$으로 대체할 수 있다.  
그러면 아래와 같은 식으로 바꿔 쓸 수 있다.  

$$y_{T+2} = \hat{y}_{T+2|T+1} + e_{T+2}$$

여기서 $e_{T+2}$는 잔차 집합에서 가져온 다른 잔차이며, 이런 방식으로 시계열 데이터에서 전체 미래 값을 시뮬레이션 할 수 있다.  

이런 반복을 통하여 미래 예측값을 얻을 수 있으며, 이는 `generate()`함수로 구현가능하다.  

```{r}
fit <- 
    google_2015 %>% 
    model(NAIVE(Close))

sim <- 
    fit %>% generate(h = 30, times =5, bootstrap = TRUE)

sim


```


`generate()`함수를 실행하면 향후 30일간(h=30)의 거래일 동안 가능한 5가지의 예측이 생성된다.  
`.rep` 열의 값이 tsibble에서 새로운 키로 주워지고, 이를 기준으로 아래와 같이 각 예측 경로를 그릴 수 있다.  

```{r}
google_2015 %>% 
    ggplot(aes(x = day)) +
    geom_line(aes(y = Close)) +
    geom_line(aes(y = .sim, color = as.factor(.rep)), data = sim) +
    labs(title = "Google daily closing stock price", y = "$US") +
    guides(color = "none")



```


plotting을 한 다음 각 예측기간에 대한 미래 샘플 경로의 백분위수를 계산하여 prediction intervals을 계산할 수 있다.  
결과를 'bootstraped prediction interval'이라 하고 이 과정을 통해 과거 데이터만 사용할 때 미래의 불확실성이 어떤 식으로 나타나는지 확인할 수 있다.  

이 과정은 `generate()`함수를 사용하지 않고 바로 `forecast()`함수를 사용해서 구현이 가능하다.  

```{r}
fc <- 
    fit %>% 
    forecast(h = 30, bootstrap = TRUE)

fc
```

결과로 예측분포가 5000개의 경로가 있는 시뮬레이션으로 표시된다.  
정규성 가정이 없기 때문(no normality assumption)에 예측구간은 대칭이 아니고, `.mean`열은 Bootstrap sample의 평균이므로 Bootstrap을 사용하지 않고 얻은 결과와 다를 수 있다.  


```{r}
autoplot(fc, google_2015) + 
    labs(title = "Google daily closing stock price", y = "$US")

```


sample의 수는 `forecast()`함수를 사용할 때 'times' argument로 조절이 가능하다.  
예를 들어 1000개의 Bootstrap samples을 생성하고 싶다면 아래와 같이 쓸 수 있다.  

```{r}
google_2015 %>% 
    model(NAIVE(Close)) %>% 
    forecast(h = 10, bootstrap = TRUE, times = 1000) %>% 
    hilo()

```













