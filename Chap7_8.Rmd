---
title: "Chap7_8"
author: "J.H AHN"
date: '2021 12 17 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 7.8 Correlation, causation and forecasting


### Correlation is not causation

상관관계와 인과관계 또는 인과관계와 예측을 혼동하지 않는 것은 중요하다.  
변수 $x$는 변수$y$를 예측하는데 유용하지만 $x$가 $y$를 초래하는 원인이라고 볼 수는 없다.  
$x$가 $y$를 야기시킬 수도 있지만 $y$가 $x$를 야기시킬 수도 있고, 이 둘의 관계가 단순한 인과관계가 아닌 더 복잡할 수도 있다.  


예를 들어, 같은 기간에 판매된 아이스크림의 수로 매월 해변 휴양지에서 익사하는 수를 모델링하는 것이 가능하다.  
이 모델은 아이스크림이 익사를 유발하기 때문이 아니라 사람들이 수영을 할 가능성이 더 높은 더운 날에 아이스크림을 더 많이 먹기 때문에 합리적인 예측을 제공할 수 있다.  
따라서 두 변수(아이스크림 판매 및 익사)는 상관관계가 있지만 하나가 다른 변수를 일으키지는 않는다.  
둘 다 제3의 변수(온도)에 의해 발생하는 것으로 생략된 변수가 응답 변수와 하나 이상의 예측 변수 모두에서 변경을 일으키는 "교란(confounding)"의 예입니다.


예측 모델에 포함되지 않은 변수가 응답 변수와 하나 이상의 예측 변수 모두에 영향을 미칠 때 **교란요인(confounder)**으로 설명한다.  
교란은 어떤 변수가 다른 변수의 변화를 일으키는지 결정하기 어렵게 만들지만 반드시 예측을 더 어렵게 만드는 것은 아니다.


마찬가지로 아침에 도로에 자전거를 타는 사람의 수를 관찰하여 오후에 비가 올지 예측할 수 있다.  
자전거 이용자가 평소보다 적으면 오후에 비가 올 가능성이 더 크다.  
이 모델은 자전거 이용자가 비를 방지하기 때문이 아니라 발표된 일기 예보가 건조한 날일 때 자전거를 탈 가능성이 더 높기 때문에 합리적인 예측을 제공할 수 있다.  
이 경우 인과 관계가 있지만 예측 모델과 반대 방향이다.  
비 예보가 있었다면 자전거 이용자는 줄어든다.  
$y$(비)가 $x$(자전거 이용자)에 영향을 미친다는 것이다.  


두 변수 사이에 인과 관계가 없거나 인과 관계가 모델과 반대 방향으로 진행되거나 교란이 있는 경우에도 상관 관계가 예측에 유용하다는 것을 이해하는 것이 중요하다.


그러나 인과 관계가 결정될 수 있다면 종종 더 나은 모델이 가능하다.  
익사에 대한 더 나은 모델은 온도와 방문자 수를 포함하고 아이스크림 판매를 제외할 것이다.  
강우량에 대한 좋은 예측 모델에는 자전거 타는 사람이 포함되지 않지만 지난 며칠 동안의 대기 관측이 포함된다.





### Forecasting with correlated predictors

둘 이상의 예측 변수가 높은 상관 관계가 있는 경우 개별 효과를 정확하게 분리하는 것이 항상 어렵다.  
2000년에서 2011년 사이의 데이터를 사용하여 2012년 회사의 월별 매출을 예측한다고 가정한다.  
2008년 1월에 새로운 경쟁자가 시장에 등장하여 시장 점유율을 일부 차지하기 시작했다.  

동시에 경제는 쇠퇴하기 시작했다면 예측 모델에는 경쟁자 활동(지역 텔레비전 방송국의 광고 시간을 사용하여 측정)과 경제 상태(GDP를 사용하여 측정)를 모두 포함한다.  
이 두 예측 변수의 효과는 상관 관계가 높기 때문에 분리할 수 없다.  



상관된 예측 변수를 갖는 것은 예측에 실제로 문제가 되지 않는다.  
예측 변수의 효과를 분리할 필요 없이 예측을 계속 계산할 수 있기 때문이다.   
그러나 시나리오는 예측 변수 간의 관계를 고려해야 하므로 시나리오 예측에 문제가 된다.  
다양한 예측 변수의 기여도에 대한 과거 분석이 필요한 경우에도 문제가 된다.  








### Multicollinearity and forecasting

이와 밀접하게 관련된 문제는 **다중공선성(multicollinearity)**이다.  
이는 다중 회귀에서 둘 이상의 예측 변수가 유사한 정보를 제공할 때 발생한다.  


두 예측 변수가 서로 높은 상관 관계가 있는 경우(즉, 상관 계수가 +1 또는 -1에 가까울 때) 발생할 수 있다.  
이 경우 변수 중 하나의 값을 알면 다른 변수의 값에 대해 많은 것을 알 수 있다.  
따라서 유사한 정보를 제공하고 있다.  
예를 들어, 발 크기를 사용하여 키를 예측할 수 있지만 동일한 모델에 왼발과 오른발의 크기를 모두 포함하면 예측이 더 나빠지지는 않지만 예측이 더 좋아지지는 않는다.  


다중 공선성은 예측 변수의 선형 조합이 예측 변수의 다른 선형 조합과 높은 상관 관계가 있는 경우에도 발생할 수 있다.  
이 경우 첫 번째 예측 변수 그룹의 값을 알면 두 번째 예측 변수 그룹의 값에 대해 많은 것을 알 수 있다.  
따라서 유사한 정보를 제공하고 있습니다.  



예를 들어 Chap7_4에서 다루었던 더미변수트랩이 있다.  
분기별로 더미변수를 $d_{1}$,$d_{2}$,$d_{3}$,$d_{4}$로 만들었다고 하자.  
$d_4=1-d_1-d_2-d_3$이 되기 때문에 $d_4$는 $d_1+d_2+d_3$과 완벽한 상관관계를 가진다.   

완전 상관의 경우(즉, 더미 변수 트랩과 같이 +1 또는 -1의 상관) 회귀 모델을 추정할 수 없다.  


높은 상관 관계가 있는 경우(+1 또는 -1에 가깝지만 같지 않음) 회귀 계수의 추정은 계산적으로 어렵다.  
사실, 일부 소프트웨어(특히 Microsoft Excel)는 계수의 매우 부정확한 추정치를 제공할 수 있다.  
대부분의 평판이 좋은 통계 소프트웨어는 알고리즘을 사용하여 계수 추정값에 대한 다중 공선성의 영향을 제한하지만 주의해야 한다.  
R, SPSS, SAS 및 Stata와 같은 주요 소프트웨어 패키지는 모두 가능한 한 문제를 피하기 위해 추정 알고리즘을 사용한다.  


다중 공선성이 존재할 때 개별 회귀 계수와 관련된 불확실성이 커진다.  
추정하기 어렵기 때문입니다. 결과적으로 회귀 계수에 대한 통계적 검정(예: t-검정)은 신뢰할 수 없다. (예측에서 우리는 그러한 테스트에 거의 관심이 없다.) 또한 예측에 대한 각 개별 예측자의 기여도에 대해 정확한 설명을 하는 것이 불가능하다.  



미래 예측 변수의 값이 predictor의 과거 값 범위를 벗어나면 예측을 신뢰할 수 없다.  
예를 들어 회귀 모델을 서로 높은 상관관계를 가진 predictor $x_1$, $x_2$로 피팅했다고 가정하고 $x_1$은 training data에서 0에서 100사이의 값을 가진다고 해보자.  
그러면 $x_{1}>100$ 혹은 $x_{1}<0$ 구간은 신뢰할 수 없다.  
예측 변수의 미래 값이 역사적 범위를 훨씬 벗어나면 항상 약간 위험하지만 다중 공선성이 있는 경우 특히 문제가 된다.  


만약 좋은 통계 소프트웨어를 사용하고, 각 예측 변수의 특정 기여에 관심이 없고 예측 변수의 미래 값이 과거 범위 내에 있다면 걱정할 필요가 없다.  - 다중공선성은 완벽한 상관관계를 가지고 있을 때를 제외하고는 문제가 되지 않는다.  




















---






